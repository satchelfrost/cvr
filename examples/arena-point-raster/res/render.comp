#version 450

#extension GL_ARB_gpu_shader_int64 : enable
#extension GL_EXT_shader_atomic_int64 : enable

layout(push_constant) uniform constants
{
    uint offset;
    uint point_count;
} push_const;

struct Vertex {
    float x, y, z;
    uint color;
};

/*
* Shader Modes
* -----
* 0 - Base model mode
* 1 - Progressive color based on number of cameras that can see a point
* 2 - Single texture mode, i.e. texture from single cctv
* 3 - Multi-texture mode
*/
layout(binding = 0) uniform uniform_data {
    mat4 mvp; // main viewing camera
    mat4 mvps[4]; // cctvs
    int shader_mode;
    int cam_order_0; // index of closest cctv to main viewing camera
    int cam_order_1;
    int cam_order_2;
    int cam_order_3; // index of furthest cctv from main viewing camera
    //ivec3 image_size;
} ubo;

layout(std430, binding = 1) buffer vert_data {
   Vertex vertices[ ];
};

layout(std430, binding = 2) buffer frame_data {
   uint64_t frame_buff[ ];
};

layout(binding = 3) uniform sampler2D tex_sampler_0;
layout(binding = 4) uniform sampler2D tex_sampler_1;
layout(binding = 5) uniform sampler2D tex_sampler_2;
layout(binding = 6) uniform sampler2D tex_sampler_3;

vec4 tex_colors[4];
int cam_sees[4];

layout(local_size_x = 1024, local_size_y = 1, local_size_z = 1) in;

uint vec3_to_uint(vec3 color)
{
    color = color * 255;
    return uint(color.b) << 16 | uint(color.g) << 8 | uint(color.r);
}

void main()
{
    uint index = gl_GlobalInvocationID.x + push_const.offset;
    if (index > push_const.point_count) return;
    Vertex vert = vertices[index];
    vec4 pos = ubo.mvp * vec4(vert.x, vert.y, vert.z, 1.0);
    vec3 ndc = pos.xyz / pos.w;

    if (pos.w <= 0 || ndc.x < -1.0 || ndc.x > 1.0 || ndc.y < -1.0 || ndc.y > 1.0)
        return;

    /* determine the color of the point cloud (model, debug, single-texture, or multi-texture) */
    vec4 cam0_pos = ubo.mvps[0] * vec4(vert.x, vert.y, vert.z, 1.0);
    vec4 cam1_pos = ubo.mvps[1] * vec4(vert.x, vert.y, vert.z, 1.0);
    vec4 cam2_pos = ubo.mvps[2] * vec4(vert.x, vert.y, vert.z, 1.0);
    vec4 cam3_pos = ubo.mvps[3] * vec4(vert.x, vert.y, vert.z, 1.0);
    vec3 ndc_0 = cam0_pos.xyz / cam0_pos.w;
    vec3 ndc_1 = cam1_pos.xyz / cam1_pos.w;
    vec3 ndc_2 = cam2_pos.xyz / cam2_pos.w;
    vec3 ndc_3 = cam3_pos.xyz / cam3_pos.w;
    vec2 uv_0 = (ndc_0.xy * 0.5) + 0.5;
    vec2 uv_1 = (ndc_1.xy * 0.5) + 0.5;
    vec2 uv_2 = (ndc_2.xy * 0.5) + 0.5;
    vec2 uv_3 = (ndc_3.xy * 0.5) + 0.5;
    tex_colors[0] = textureLod(tex_sampler_0, uv_0, 0.0);
    tex_colors[1] = textureLod(tex_sampler_1, uv_1, 0.0);
    tex_colors[2] = textureLod(tex_sampler_2, uv_2, 0.0);
    tex_colors[3] = textureLod(tex_sampler_3, uv_3, 0.0);

    cam_sees[0] = int((-cam0_pos.w < cam0_pos.x && cam0_pos.x < cam0_pos.w) &&
                      (-cam0_pos.w < cam0_pos.y && cam0_pos.y < cam0_pos.w) &&
                      (-cam0_pos.w < cam0_pos.z && cam0_pos.z < cam0_pos.w));
    cam_sees[1] = int((-cam1_pos.w < cam1_pos.x && cam1_pos.x < cam1_pos.w) &&
                      (-cam1_pos.w < cam1_pos.y && cam1_pos.y < cam1_pos.w) &&
                      (-cam1_pos.w < cam1_pos.z && cam1_pos.z < cam1_pos.w));
    cam_sees[2] = int((-cam2_pos.w < cam2_pos.x && cam2_pos.x < cam2_pos.w) &&
                      (-cam2_pos.w < cam2_pos.y && cam2_pos.y < cam2_pos.w) &&
                      (-cam2_pos.w < cam2_pos.z && cam2_pos.z < cam2_pos.w));
    cam_sees[3] = int((-cam3_pos.w < cam3_pos.x && cam3_pos.x < cam3_pos.w) &&
                      (-cam3_pos.w < cam3_pos.y && cam3_pos.y < cam3_pos.w) &&
                      (-cam3_pos.w < cam3_pos.z && cam3_pos.z < cam3_pos.w));

    uint brightness = uint((cam_sees[0] * 0.25 + cam_sees[1] * 0.25 + cam_sees[2] * 0.25 + cam_sees[3] * 0.25) * 255.0);
    uint out_color = 0;
    //out_color = (cam_sees[ubo.cam_order_0] > 0) ? vec3_to_uint(tex_colors[ubo.cam_order_0].rgb) : vert.color;
    switch (ubo.shader_mode) {
    case 0:
        out_color = vert.color;
        break;
    case 1:
        out_color = brightness << 16 | brightness << 8 | brightness;
        break;
    case 2:
        out_color = (cam_sees[ubo.cam_order_0] > 0) ? vec3_to_uint(tex_colors[ubo.cam_order_0].rgb) : vert.color;
        //out_color = (cam_sees[ubo.cam_order_0] > 0) ? tex_buff[tex_id] : vert.color;
        break;
    case 3:
        if (cam_sees[ubo.cam_order_3] > 0) out_color = vec3_to_uint(tex_colors[ubo.cam_order_3].rgb);
        if (cam_sees[ubo.cam_order_2] > 0) out_color = vec3_to_uint(tex_colors[ubo.cam_order_2].rgb);
        if (cam_sees[ubo.cam_order_1] > 0) out_color = vec3_to_uint(tex_colors[ubo.cam_order_1].rgb);
        if (cam_sees[ubo.cam_order_0] > 0) out_color = vec3_to_uint(tex_colors[ubo.cam_order_0].rgb);
        int cam_count = cam_sees[0] + cam_sees[1] + cam_sees[2] + cam_sees[3];
        if (cam_count == 0) out_color = vert.color;
    }

    /* determine the pixel coordinate and write to framebuffer */
    ivec2 img_size = ivec2(1600, 900);
    vec2 img_pos = (ndc.xy * 0.5 + 0.5) * img_size;
    ivec2 pixel_coords = ivec2(img_pos);
    int pixel_id = pixel_coords.x + pixel_coords.y * img_size.x;
    uint64_t depth = floatBitsToUint(pos.w);
    uint64_t old_depth = frame_buff[pixel_id] >> 32;

    if (depth < old_depth) {
        uint64_t packed = depth << 32 | uint64_t(out_color);
        atomicMin(frame_buff[pixel_id], packed);
    }
}
