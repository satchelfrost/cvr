#version 450

#extension GL_ARB_gpu_shader_int64 : enable
#extension GL_EXT_shader_atomic_int64 : enable

#define NUM_CCTVS 4
#define NUM_VIDEO_PLANES 3

vec4 tex_colors[NUM_CCTVS];
int cam_sees[NUM_CCTVS];
vec4 cam_clip[NUM_CCTVS];

layout(push_constant) uniform constants
{
    uint offset;
    uint point_count;
} push_const;

struct Vertex {
    float x, y, z;
    uint color;
};

/*
* Shader Modes
* -----
* 0 - Base model mode
* 1 - Progressive color based on number of cameras that can see a point
* 2 - Single texture mode, i.e. texture from single cctv
* 3 - Multi-texture mode
* 4 - Multi-texture mode with blend
*/
layout(binding = 0) uniform uniform_data {
    mat4 mvp; // main viewing camera
    mat4 mvps[NUM_CCTVS]; // cctvs
    int shader_mode;
    int cam_order_0; // index of closest cctv to main viewing camera
    int cam_order_1;
    int cam_order_2;
    int cam_order_3; // index of furthest cctv from main viewing camera
    float blend_ratio;
    //ivec3 image_size;
} ubo;

layout(std430, binding = 1) buffer vert_data {
   Vertex vertices[ ];
};

layout(std430, binding = 2) buffer frame_data {
   uint64_t frame_buff[ ];
};

/* uses binding 3 -> 14 */
layout(binding = 3) uniform sampler2D samplers[NUM_CCTVS * NUM_VIDEO_PLANES];

mat4 rec601 = mat4(
    1.16438,  0.00000,  1.59603, -0.87079,
    1.16438, -0.39176, -0.81297,  0.52959,
    1.16438,  2.01723,  0.00000, -1.08139,
    0, 0, 0, 1
);

layout(local_size_x = 1024, local_size_y = 1, local_size_z = 1) in;

uint vec3_to_uint(vec3 color)
{
    color = min(color * 255, 255);
    return uint(color.b) << 16 | uint(color.g) << 8 | uint(color.r);
}

void main()
{
    uint index = gl_GlobalInvocationID.x + push_const.offset;
    if (index > push_const.point_count) return;
    Vertex vert = vertices[index];
    vec4 pos = ubo.mvp * vec4(vert.x, vert.y, vert.z, 1.0);
    vec3 ndc = pos.xyz / pos.w;

    if (pos.w <= 0 || ndc.x < -1.0 || ndc.x > 1.0 || ndc.y < -1.0 || ndc.y > 1.0)
        return;

    for (int i = 0; i < NUM_CCTVS; i++) {
        /* convert the vertex into each cctvs clip coordinate space */
        vec4 cam_clip = ubo.mvps[i] * vec4(vert.x, vert.y, vert.z, 1.0);
        vec3 ndc = cam_clip.xyz / cam_clip.w;
        vec2 uv = (ndc.xy * 0.5) + 0.5;

        /* calculate the final texture from the three video planes */
        float y  = textureLod(samplers[0 + i * NUM_VIDEO_PLANES], uv, 0).r;
        float cb = textureLod(samplers[1 + i * NUM_VIDEO_PLANES], uv, 0).r;
        float cr = textureLod(samplers[2 + i * NUM_VIDEO_PLANES], uv, 0).r;
        tex_colors[i] = vec4(y, cb, cr, 1.0) * rec601;

        /* determine if vertex can be seen by a particular cctv */
        cam_sees[i] = int((-cam_clip.w < cam_clip.x && cam_clip.x < cam_clip.w) &&
                          (-cam_clip.w < cam_clip.y && cam_clip.y < cam_clip.w) &&
                          (-cam_clip.w < cam_clip.z && cam_clip.z < cam_clip.w));
    }

    uint brightness = uint((cam_sees[0] * 0.25 + cam_sees[1] * 0.25 + cam_sees[2] * 0.25 + cam_sees[3] * 0.25) * 255.0);
    uint out_color = vert.color;
    vec4 temp_mix;
    float ratio_color;
    switch (ubo.shader_mode) {
    case 0:
        break;
    case 1:
        out_color = brightness << 16 | brightness << 8 | brightness;
        break;
    case 2:
        out_color = (cam_sees[ubo.cam_order_0] > 0) ? vec3_to_uint(tex_colors[ubo.cam_order_0].rgb) : vert.color;
        break;
    case 3:
        if (cam_sees[ubo.cam_order_3] > 0) out_color = vec3_to_uint(tex_colors[ubo.cam_order_3].rgb);
        if (cam_sees[ubo.cam_order_2] > 0) out_color = vec3_to_uint(tex_colors[ubo.cam_order_2].rgb);
        if (cam_sees[ubo.cam_order_1] > 0) out_color = vec3_to_uint(tex_colors[ubo.cam_order_1].rgb);
        if (cam_sees[ubo.cam_order_0] > 0) out_color = vec3_to_uint(tex_colors[ubo.cam_order_0].rgb);
        break;
    case 4:
        if (cam_sees[ubo.cam_order_3] > 0) out_color = vec3_to_uint(tex_colors[ubo.cam_order_3].rgb);
        if (cam_sees[ubo.cam_order_2] > 0) out_color = vec3_to_uint(tex_colors[ubo.cam_order_2].rgb);
        if (cam_sees[ubo.cam_order_1] > 0) out_color = vec3_to_uint(tex_colors[ubo.cam_order_1].rgb);
        ratio_color = smoothstep(0.35, 0.65, ubo.blend_ratio);
        temp_mix = mix(tex_colors[ubo.cam_order_0], tex_colors[ubo.cam_order_1], ratio_color);
        if (cam_sees[ubo.cam_order_0] > 0) {
            out_color = (cam_sees[ubo.cam_order_1] > 0) ? vec3_to_uint(temp_mix.rgb) : vec3_to_uint(tex_colors[ubo.cam_order_0].rgb);
        }
        break;
    }

    /* determine the pixel coordinate and write to framebuffer */
    ivec2 img_size = ivec2(1600, 900);
    vec2 img_pos = (ndc.xy * 0.5 + 0.5) * img_size;
    ivec2 pixel_coords = ivec2(img_pos);
    int pixel_id = pixel_coords.x + pixel_coords.y * img_size.x;
    uint64_t depth = floatBitsToUint(pos.w);
    uint64_t old_depth = frame_buff[pixel_id] >> 32;

    if (depth < old_depth) {
        uint64_t packed = depth << 32 | uint64_t(out_color);
        atomicMin(frame_buff[pixel_id], packed);
    }
}
